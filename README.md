### Hi there, I am Dongxian WU (å´æ ‹è´¤ in Chinese) ğŸ‘‹

I am an enthusiast for building a trustworthy AI system. I received my PhD degree in the Department of Computer Science and Technology at Tsinghua University, co-supervised by Prof. [Shu-Tao Xia](https://scholar.google.com/citations?user=koAXTXgAAAAJ&hl=en) and Prof. [Yisen Wang](https://sites.google.com/site/csyisenwang/). Currently, I am a Project Researcher at the University of Tokyo, supervised by Prof. [Masashi Sugiyama](http://www.ms.k.u-tokyo.ac.jp/sugi/index.html).

ğŸ”­ My research mainly focus on:
- adversarial attacks and defenses
- data security, especially backdoor attacks and defenses
- weakly supervised learning, especially noisy labels

ğŸ“« Reach me by:
- d.wu@k.u-tokyo.ac.jp
- wudx16@gmail.com


ğŸ’¬ News:

- **Aug 2021**: I join the [Sugiyama-Yokoya-Ishida](http://www.ms.k.u-tokyo.ac.jp/index.html) Lab to be a Project Researcher at the University of Tokyo ğŸ—».

- **Jun 2021**: I pass the defense and receive my PhD degree ğŸ“ in the Department of Computer Science and Technology at Tsinghua University.

- **Oct 2020**: Our team (Dongxian Wu, Yisen Wang, Yanjie Li, Bin Chen) won the 1st prize in the 2020 [GeekPwn CAAD AI magic mask competition](http://hof.geekpwn.org/zh/index.html). This is an interesting competition where competitors craft adversarial masks to confuse the face recognition system (See [news](https://www.mgtv.com/b/334872/10358357.html?fpa=se&lastp=so_result) on Manguo (Hunan) TV). We will release our codes soon.

- **Sep 2020**: Our paper "Adversarial Weight Perturbation Helps Robsut Generalization" ([paper](https://papers.nips.cc/paper/2020/hash/1ef91c212e30e14bf125e9374262401f-Abstract.html), [arXiv](https://arxiv.org/pdf/2004.05884.pdf), [code](https://github.com/csdongxian/AWP)) has been accepted by NeurIPS 2020.

- **Jul 2020**: Our paper "Targeted Attack for Deep Hashing based Retrieval" ([arXiv](https://arxiv.org/pdf/2004.07955.pdf), [code](https://github.com/jiawangbai/DHTA-master)) has been accepted by ECCV 2020 as oral (top 2%).

- **Dec 2019**: Our paper "Skip Connections Matter: On the Transferability of Adversarial Examples Generated with Resnets" ([paper](https://openreview.net/forum?id=BJlRs34Fvr), [arXiv](https://arxiv.org/pdf/2002.05990.pdf),  [code](https://github.com/csdongxian/skip-connections-matter)) has been accepted by ICLR 2020 as spotlight (top 6%).
